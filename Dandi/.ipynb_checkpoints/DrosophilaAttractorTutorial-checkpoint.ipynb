{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TVknMWS_YVWg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVknMWS_YVWg",
    "outputId": "4179859e-5e73-4868-a0c6-26ce9beba8cc"
   },
   "outputs": [],
   "source": [
    "!pip install dandi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f26bd-6dee-4d5f-8e97-815fe67b17e9",
   "metadata": {
    "id": "4e8f26bd-6dee-4d5f-8e97-815fe67b17e9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "import pandas as pd\n",
    "from scipy.stats import circmean\n",
    "\n",
    "# DANDI\n",
    "import fsspec\n",
    "import h5py\n",
    "from fsspec.implementations.cached import CachingFileSystem\n",
    "from pynwb import NWBHDF5IO\n",
    "from dandi.dandiapi import DandiAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c8c20-95b2-4efb-8907-bb3e47a7225e",
   "metadata": {
    "id": "e39c8c20-95b2-4efb-8907-bb3e47a7225e"
   },
   "source": [
    "# General overview of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a2804-5883-4528-adb4-d9249aae6303",
   "metadata": {
    "id": "3e1a2804-5883-4528-adb4-d9249aae6303"
   },
   "source": [
    "The PhD thesis underlying this [DANDI-datset](https://dandiarchive.org/dandiset/000289?search=drosophila&page=1&sortOption=0&sortDir=-1&showDrafts=true&showEmpty=true&pos=3) can be found [here (Basnak, 2022)](https://dash.harvard.edu/server/api/core/bitstreams/2d87ca6c-ffb5-4b51-aabe-1216ae3416cb/content). The thesis focuses on how the fruit fly head direction circuit accounts for bump-attractor like dynamics coding for the location of the animal. If you're interested in the details of how undertainty is encoded in the head direction cells, check out the thesis.\n",
    "\n",
    "In the set-up, the flies were head-fixed and positioned on a freely moving ball in a virtual reality surrounding while being recorded with two-photon Calcium imaging (panel B). A stimulus stripe of varying brightness (high, low, zero) was presented and rotated around the fly with the fly's own rotational velocity, mimicking the movement of the fly while allowing for a head-fixed set-up, as illustated in (panel C). The protocerebral bridge and the ellipsoid body of the fly are known to reflect its head-direction cells (panel A).\n",
    "![image](https://github.com/shepai/BIORTC_Nigeria/blob/main/Dandi/TaskSetup.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650efabe-5fe5-4d63-ae5a-287ebbf25ee6",
   "metadata": {
    "id": "650efabe-5fe5-4d63-ae5a-287ebbf25ee6"
   },
   "source": [
    "Here, we mostly want to show you how to load the data set. However, for analyzing new data it's important to learn about the dataset, data aquisition, imaging methods etc. So it is usually a good start to read the additional information like the PhD thesis. However, for this quick tutorial we will skip most of the details. Just note that if you were to start a project on this data, you should definitely do more research or even reach out to the dataset author."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd14b6-2bc9-4a03-b64f-4aeb6543beb5",
   "metadata": {
    "id": "a6bd14b6-2bc9-4a03-b64f-4aeb6543beb5"
   },
   "source": [
    "# Load the behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ba304-7d2d-4dfa-8f67-373e97b0c7aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d5ba304-7d2d-4dfa-8f67-373e97b0c7aa",
    "outputId": "e0a9ede0-39ce-407a-e764-390ecc9125b6"
   },
   "outputs": [],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "\n",
    "# get dataset ID, filename of a session of interest from https://dandiarchive.org/\n",
    "dandiset_id = '000289'\n",
    "file_path = \"sub-2/sub-2_ses-20201020T000000_behavior+ophys.nwb\" # file size ~67GB\n",
    "\n",
    "# This is how the DANDI API can be used to load data, it is always the same for all datasets\n",
    "with DandiAPIClient() as client:\n",
    "    asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(file_path)\n",
    "    s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "\n",
    "# Create a virtual filesystem based on the http protocol and use caching to save accessed data to RAM.\n",
    "# No need to understand in depth, this is just how you load nwb datasets\n",
    "fs = fsspec.filesystem(\"http\")\n",
    "file_system = fs.open(s3_url, \"rb\")\n",
    "file = h5py.File(file_system, mode=\"r\")\n",
    "# Open the file with NWBHDF5IO\n",
    "io = NWBHDF5IO(file=file, load_namespaces=True)\n",
    "\n",
    "nwb = io.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00c981-b9b5-42a6-ac81-150e78357cda",
   "metadata": {
    "id": "ce00c981-b9b5-42a6-ac81-150e78357cda"
   },
   "source": [
    "If we print the loaded file, we can see which information is provided. Klick on the different subsections to get an intuition on what is saved where. For example, most nwb files contain the behavioral information in the **trials** subsection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617813c-98c8-463a-9fc1-795d9929b4d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "5617813c-98c8-463a-9fc1-795d9929b4d3",
    "outputId": "a4639658-6a01-4544-f4b8-4701fbda5f98"
   },
   "outputs": [],
   "source": [
    "# print the file to get a general, browsable overview\n",
    "nwb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bdba48-167a-43d4-84f8-9a7cb7e6c10d",
   "metadata": {
    "id": "61bdba48-167a-43d4-84f8-9a7cb7e6c10d"
   },
   "source": [
    "You can load the trial structure information into a dataframe in the following manner. It tells you when a trial starts, when it ends and the amount of contrast in each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46162393-bd4c-4dd0-8334-0b35516e1496",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "46162393-bd4c-4dd0-8334-0b35516e1496",
    "outputId": "09d6fa95-5ec7-41b1-c1d1-e20c53d5b87c"
   },
   "outputs": [],
   "source": [
    "trials = nwb.trials\n",
    "df_trials = trials.to_dataframe() # generate a dataframe out of nwb subsection\n",
    "df_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb83ce4-c6b5-47c6-b952-2803dca56afa",
   "metadata": {
    "id": "ffb83ce4-c6b5-47c6-b952-2803dca56afa"
   },
   "source": [
    "### Load the animal's behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a176812-877a-4947-8b04-ef913fa73c9d",
   "metadata": {
    "id": "6a176812-877a-4947-8b04-ef913fa73c9d"
   },
   "source": [
    "We now want to access what the animal was doing during the trials. After looking into the nwb file and browsing a bit, we find that there is a lot of information in the \"processing\" sub-channel. Can you find how to get the data?\n",
    "\n",
    "**Tip:** Once you have something in the shape of an HDF5 file you can convert it to an array using the np.array() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d76aa4-7fb5-4b2c-a454-709c9c7c01a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "09d76aa4-7fb5-4b2c-a454-709c9c7c01a2",
    "outputId": "7aaf0655-8629-4deb-d05e-6392511163f3"
   },
   "outputs": [],
   "source": [
    "# get the time stamp of each movement\n",
    "turning_time = np.array(nwb.processing['behavior'].data_interfaces['Position'].spatial_series['SpatialSeries'].timestamps)\n",
    "# get the turning direction in radians (0 is centered at the stimulus)\n",
    "turning_direction = np.array(nwb.processing['behavior'].data_interfaces['Position'].spatial_series['SpatialSeries'].data)\n",
    "# turn tunring direction to [-pi, pi] while maintaing 0 as facing the stimulus location\n",
    "turning_direction[turning_direction>np.pi] = turning_direction[turning_direction>np.pi]-2*np.pi\n",
    "\n",
    "# turn into dataframe\n",
    "dict_behav = {'time': turning_time, 'behavior': turning_direction}\n",
    "df_behav = pd.DataFrame(dict_behav)\n",
    "# convert time into minutes for ease of use\n",
    "df_behav['time_min'] = (df_behav.time)/60\n",
    "# add the stimulus (from the previous step) to the behavioral dataframe\n",
    "df_behav['stimulus'] = np.zeros((len(df_behav)))\n",
    "for trial in df_trials.index: # for each trial\n",
    "    # if the behavior happens during the trial's time, add the stimulus to the dataframe\n",
    "    df_behav.loc[np.where((df_behav.time >= df_trials.start_time[trial]) &\\\n",
    "                           (df_behav.time <= df_trials.stop_time[trial]))[0], 'stimulus'] = df_trials.cue_contrast[trial]\n",
    "df_behav.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cff61a-92dd-422c-96c0-0c5c7b140f8f",
   "metadata": {
    "id": "61cff61a-92dd-422c-96c0-0c5c7b140f8f"
   },
   "source": [
    "Let's plot the animals heading direction through a full session. The top bars indicate the stimulus strength (the more blue, the stronger the stimulus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e21ff8-1ccd-4173-a7a4-033a86210d36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "69e21ff8-1ccd-4173-a7a4-033a86210d36",
    "outputId": "09369517-1c97-4693-982b-4b3ea6bda240"
   },
   "outputs": [],
   "source": [
    "plot(df_behav.time_min, np.rad2deg(df_behav.behavior), color='k', alpha=0.75)\n",
    "xlabel('time from trial start (min)')\n",
    "ylabel('visual cue position (Â°)')\n",
    "\n",
    "# fill-in the stimulus strength\n",
    "stim_colors = [np.nan, 'lightcyan', 'skyblue', 'deepskyblue']\n",
    "for i in df_trials.index:\n",
    "    fill_between([df_trials.start_time[i]/60, df_trials.stop_time[i]/60], [185, 185], [190, 190],\\\n",
    "                 alpha=0.5, color=stim_colors[int(df_trials.cue_contrast[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ecd280-7769-4d31-9510-66df2df66a3b",
   "metadata": {
    "id": "19ecd280-7769-4d31-9510-66df2df66a3b"
   },
   "source": [
    "Wow, that's quite noisy. No worries, we will take care of that in a bit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4926ef-76eb-457f-a3e5-5792c8d0009f",
   "metadata": {
    "id": "6b4926ef-76eb-457f-a3e5-5792c8d0009f"
   },
   "source": [
    "# Neural data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652e694-b247-40c5-ba94-e760b2df7f16",
   "metadata": {
    "id": "d652e694-b247-40c5-ba94-e760b2df7f16"
   },
   "source": [
    "Let's load the neural data. Again, check in the browsable nwb file ($\\uparrow$) to find how to access the data.\n",
    "\n",
    "**Tip:** Start at processing.ophys and see if you can find some neural data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded7a2a-0845-4b43-95f4-1e3a6dd6f61f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9ded7a2a-0845-4b43-95f4-1e3a6dd6f61f",
    "outputId": "b17d0073-7ea5-422d-cb30-6662cd696e63"
   },
   "outputs": [],
   "source": [
    "# get the neural firing (tip: there are 41 ROIs in this session, half for the left PB, half for the right)\n",
    "neural_direction = np.array(nwb.processing['ophys'].data_interfaces['Fluorescence'].roi_response_series['RoiResponseSeries'].data)\n",
    "change = int(neural_direction.shape[1]/2)\n",
    "# get the time stamps\n",
    "neural_timing = np.array(nwb.processing['ophys'].data_interfaces['Fluorescence'].roi_response_series['RoiResponseSeries'].timestamps)\n",
    "\n",
    "# turn into neural dataframe\n",
    "dict_neural = {'time': neural_timing, 'neural': [neural_direction[i] for i in range(len(neural_direction))]}\n",
    "df_neural = pd.DataFrame(dict_neural)\n",
    "df_neural['time_min'] = (df_neural.time - np.min(df_neural.time))/60\n",
    "\n",
    "df_neural.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241bc272-5357-4217-9766-901877ba0bc7",
   "metadata": {
    "id": "241bc272-5357-4217-9766-901877ba0bc7"
   },
   "source": [
    "### Smooth the neural and behavioral data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548990e-fa37-44de-b9d5-ca92fe1f0c0d",
   "metadata": {
    "id": "e548990e-fa37-44de-b9d5-ca92fe1f0c0d"
   },
   "source": [
    "For a better overview of the dynamics, we want to smooth the time axis. Instead of having 120ms steps, we want to have 5s timesteps and apply a smoothing window of 10s. These times might be quite large but we first want to gain a general overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7a341-3900-46c5-90df-360986219709",
   "metadata": {
    "id": "24b7a341-3900-46c5-90df-360986219709"
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "smoothed_time = []\n",
    "smoothed_behav = []\n",
    "smoothed_neural = []\n",
    "smoothed_stimulus = []\n",
    "\n",
    "w_step = 0.1 / 60 # 5s steps converted to minutes\n",
    "w_width = 0.2 / 60 # 10s window converted to minutes\n",
    "# for each time step, get the data in question and average it in the specified time window\n",
    "for steps in np.arange(0, df_neural.time_min.max() ,w_step):\n",
    "    df_b = df_behav.loc[(df_behav.time_min > steps) & (df_behav.time_min <= steps+w_width)]\n",
    "    df_n = df_neural.loc[(df_neural.time_min > steps) & (df_neural.time_min <= steps+w_width)]\n",
    "\n",
    "    # for each time step save the averaged data to a list\n",
    "    smoothed_time.append(np.mean(df_b.time_min))\n",
    "    smoothed_behav.append(circmean(df_b.behavior, low=-np.pi, high=np.pi))\n",
    "    smoothed_neural.append(np.mean(df_n.neural, axis=0))\n",
    "    smoothed_stimulus.append(np.mean(df_b.stimulus))\n",
    "\n",
    "# generate a smoothed dataframe\n",
    "dict_smoothed = {'time_min': smoothed_time, 'behavior': smoothed_behav, 'neural': smoothed_neural, 'stimulus': smoothed_stimulus}\n",
    "df_smoothed = pd.DataFrame(dict_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb39bf-796a-41cd-a7b2-41161e22b2f9",
   "metadata": {
    "id": "49eb39bf-796a-41cd-a7b2-41161e22b2f9"
   },
   "source": [
    "### Plot the neural firing rates and the heading direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2cb38-7c9e-4112-be28-7509c24e2607",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "id": "ead2cb38-7c9e-4112-be28-7509c24e2607",
    "outputId": "e41ac667-2b57-4162-bd14-3be18cc835eb"
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "# split into left and right PB (they are mirror copies of each other)\n",
    "leftPB = np.array([df_smoothed.neural[i][:change] for i in df_smoothed.index])\n",
    "rightPB = np.array([df_smoothed.neural[i][change:] for i in df_smoothed.index])\n",
    "\n",
    "# initializing a figure\n",
    "fig = figure()\n",
    "# marking the x-axis and y-axis limits\n",
    "ax = axes(xlim =(-np.pi, np.pi),\n",
    "                ylim =(np.min([leftPB, rightPB]), np.max([leftPB, rightPB])))\n",
    "\n",
    "# initializing a line, scatter variable to update\n",
    "line, = ax.plot([], [], lw = 3, color='blue', label='left PB')\n",
    "line2, = ax.plot([], [], lw = 3, color='red', label='right PB')\n",
    "scat = ax.scatter([],  [], marker='v', color='k', label='behavior')\n",
    "ax.legend(loc=3)\n",
    "\n",
    "def update(frame):\n",
    "    \"\"\"A function called on every frame:\n",
    "    Draw a\n",
    "                lineplot of the left PB activity\n",
    "                lineplot of the right PB activity\n",
    "                scatterplot of the heading direction as a tick mark\"\"\"\n",
    "    x = np.linspace(-np.pi, np.pi, len(leftPB[frame]), endpoint=False)\n",
    "    line.set_data(x, leftPB[frame,:])\n",
    "    line2.set_data(x, rightPB[frame,:])\n",
    "    scat.set_offsets([-df_smoothed.behavior[frame], 2.5])\n",
    "    return line, line2, scat\n",
    "\n",
    "# animate the activity and behavior for visualization\n",
    "ani = FuncAnimation(fig, update,\n",
    "                     frames = np.min([len(leftPB), 100]), interval = 100)#\n",
    "HTML(ani.to_html5_video())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f96f4-8515-42a2-bc40-71949d914079",
   "metadata": {
    "id": "2a0f96f4-8515-42a2-bc40-71949d914079"
   },
   "source": [
    "## That looks pretty good! Neurons are representing the heading direction of the fly pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2979822-0c99-47c4-a88f-932ee3340f52",
   "metadata": {
    "id": "b2979822-0c99-47c4-a88f-932ee3340f52"
   },
   "source": [
    "To quantify this across animals, it is usually useful to use linear regression to maximally align the neural and the behavioral space. In some sessions there might be a misalignment between the PB neural alignment and the stimulus alignment. You will learn about this in the next couple of das, so stay tuned!\n",
    "\n",
    "**Outlook:**\n",
    "We could for example use this classification to ask how *uncertainty* affects the bump dynamics based on if the displayed stimulus is strong, weak or off (as done in the PhD thesis). And other fun analyses to understand how bump attractor dynamics underlie the fly head direction system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GViIIcbdXwI_",
   "metadata": {
    "id": "GViIIcbdXwI_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
